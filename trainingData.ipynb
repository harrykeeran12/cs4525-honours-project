{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e51804ce",
   "metadata": {},
   "source": [
    "# Analysing the training data:\n",
    "\n",
    "The training data was taken from the CT-RATE reports.\n",
    "We can create synthetic data by finding which items we can change.\n",
    "\n",
    "We want a set of items that is just error-free. This must be analysed to check whether they are error-free or not, or maybe modified such that they are error-free. \n",
    "\n",
    "We also want 4 datasets that contain errors. These errors are internal inconsistencies, extraneous statements, transcription errors and omissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6595f000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current number of data to change: 23695\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import nltk\n",
    "import random\n",
    "from schema import RadiologyErrors, RadiologyError, ErrorType\n",
    "\n",
    "# Detokenises the sentence back together\n",
    "twd = nltk.TreebankWordDetokenizer()\n",
    "df = pd.read_csv(\"datasets/training_data1.csv\")\n",
    "\n",
    "itemsToChange = df[\"Correct Items\"]\n",
    "\n",
    "print(f\"Current number of data to change: {len(itemsToChange)}\")\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb11894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what words can be used to find errors:\n",
    "\n",
    "internalInconsistency = [\n",
    "    [\"anterior\", \"posterior\"],\n",
    "    [\"medial\", \"lateral\"],\n",
    "    [\"superior\", \"inferior\"],\n",
    "    [\n",
    "        \"anterolateral\",\n",
    "        \"posterolateral\",\n",
    "        \"supralateral\",\n",
    "        \"infralateral\",\n",
    "        \"anterosuperior\",\n",
    "        \"posterosuperior\",\n",
    "        \"anteroposterior\",\n",
    "    ],\n",
    "    [\n",
    "        \"anteromedial\",\n",
    "        \"posteromedial\",\n",
    "        \"supramedial\",\n",
    "        \"inframedial\",\n",
    "        \"anteroinferior\",\n",
    "        \"posteroinferior\",\n",
    "        \"posteroanterior\",\n",
    "    ],\n",
    "    [\n",
    "        \"anterior-lateral\",\n",
    "        \"posterior-lateral\",\n",
    "        \"superior-lateral\",\n",
    "        \"inferior-lateral\",\n",
    "        \"anterior-superior\",\n",
    "        \"posterior-superior\",\n",
    "    ],\n",
    "    [\n",
    "        \"anterior-medial\",\n",
    "        \"posterior-medial\",\n",
    "        \"superior-medial\",\n",
    "        \"inferior-medial\",\n",
    "        \"anterior-inferior\",\n",
    "        \"posterior-inferior\",\n",
    "    ],\n",
    "    [\"anterior-posterior\", \"medial-lateral\", \"superior-inferior\"],\n",
    "    [\"dorsal-ventral\", \"transverse\", \"craniocaudal\"],\n",
    "    [\"cranial\", \"caudal\"],\n",
    "    [\"hepatopedal\", \"hepatofugal\"],\n",
    "    [\"dorsal\", \"ventral\"],\n",
    "    [\"proximal\", \"distal\"],\n",
    "    [\"long axis\", \"short axis\"],\n",
    "    [\"peripheral\", \"central\"],\n",
    "    [\"superficial\", \"deep\"],\n",
    "    [\"metaphysis\", \"diaphysis\", \"epiphysis\"],\n",
    "    [\"ascending\", \"descending\"],\n",
    "    [\"increase\", \"decrease\"],\n",
    "    [\"increased\", \"decreased\"],\n",
    "    [\"basal\", \"apical\"],\n",
    "    [\"hyperdense\", \"hypodense\"],\n",
    "    [\"solid\", \"cystic\"],\n",
    "    [\"dependent\", \"non-dependent\"],\n",
    "    [\"upper\", \"lower\"],\n",
    "]\n",
    "\n",
    "transcription = [\n",
    "    [\"abscess\", \"access\", \"assess\"],\n",
    "    [\"achalasia\", \"atelectasis\", \"epistaxis\"],\n",
    "    [\"adrenal\", \"renal\"],\n",
    "    [\"alveolar\", \"valcular\", \"lobular\", \"tubular\"],\n",
    "    [\"aneurysm\", \"anaplasia\", \"anemia\"],\n",
    "    [\"anterolisthesis\", \"retrolisthesis\", \"spondylolisthesis\"],\n",
    "    [\"ascites\", \"cystitis\", \"bursitis\", \"colitic\"],\n",
    "    [\"aspiration\", \"eventration\"],\n",
    "    [\"atheroma\", \"myxoma\", \"osteoma\", \"lipoma\"],\n",
    "    [\"borderline\", \"baseline\"],\n",
    "    [\"bronchiectasis\", \"bronchitis\", \"bronchiolitis\", \"bronchi\"],\n",
    "    [\"bronchogenic\", \"bronchiolitic\", \"bronchoscopic\"],\n",
    "    [\"bullous\", \"mucous\"],\n",
    "    [\"calcified\", \"ossified\", \"classified\"],\n",
    "    [\"carcinomatosis,sarcomatosis\", \"carcinosis\", \"sarcoidosis\"],\n",
    "    [\"cm\", \"mm\", \"m\"],\n",
    "    [\"consolidation\", \"accumulation\", \"congestion\", \"compaction\", \"obstruction\"],\n",
    "    [\"consolidative\", \"accumulative\", \"congestive\", \"obstructive\"],\n",
    "    [\"coronary\", \"coronal\", \"coronoid\", \"coracoid\", \"corneal\"],\n",
    "    [\"corpuscles\", \"corpus\", \"corvus\", \"corpse\"],\n",
    "    [\"cortical\", \"corticoid\", \"corticate\"],\n",
    "    [\"craniocaudal\", \"craniocervical\", \"craniobasal\"],\n",
    "    [\"cyst\", \"gist\", \"list\", \"fist\"],\n",
    "    [\"cystic\", \"systolic\", \"caustic\", \"cyclic\", \"plastic\"],\n",
    "    [\"degenerative\", \"regenerative\", \"destructive\"],\n",
    "    [\"diaphragm\", \"diagram\", \"diaphysis\"],\n",
    "    [\"edematous\", \"erythematous\", \"emphysematous\"],\n",
    "    [\"effusion\", \"confusion\", \"diffusion\", \"perfusion\", \"occlusion\"],\n",
    "    [\"empyema\", \"emphysema\", \"haematoma\", \"endothelium\"],\n",
    "    [\"endobronchial\", \"endotracheal\"],\n",
    "    [\"esophagogastric\", \"esophagocolic\"],\n",
    "    [\"esophagus\", \"esophagitis\"],\n",
    "    [\n",
    "        \"fibrosis\",\n",
    "        \"stenosis\",\n",
    "        \"sclerosis\",\n",
    "        \"synostosis\",\n",
    "        \"cyanosis\",\n",
    "        \"thrombosis\",\n",
    "        \"necrosis\",\n",
    "        \"nephrosis\",\n",
    "        \"silicosis\",\n",
    "        \"cirrhosis\",\n",
    "        \"asbestosis\",\n",
    "        \"aspergillosis\",\n",
    "        \"kyphosis\",\n",
    "        \"lordosis\",\n",
    "        \"mycosis\",\n",
    "    ],\n",
    "    [\n",
    "        \"fibrotic\",\n",
    "        \"stenotic\",\n",
    "        \"sclerotic\",\n",
    "        \"cyanotic\",\n",
    "        \"thrombotic\",\n",
    "        \"necrotic\",\n",
    "        \"nephrotic\",\n",
    "        \"cirrhotic\",\n",
    "    ],\n",
    "    [\"fissure\", \"fixture\", \"fisher\", \"fistula\", \"fossa\"],\n",
    "    [\"fluid\", \"flutter\", \"fluctuant\", \"florid\"],\n",
    "    [\"fracture\", \"friction\", \"contracture\", \"rapture\"],\n",
    "    [\"fusiform\", \"reniform\"],\n",
    "    [\"gastroesophageal\", \"gastroduodenal\", \"gastrojejunal\", \"gastroepiploic\"],\n",
    "    [\"ground glass/ground-glass\", \"ground grass\", \"brown glass\", \"brown brass\"],\n",
    "    [\"hemorrhagic\", \"hemostatic\", \"hemolytic\"],\n",
    "    [\"hernia\", \"fistula\", \"myalgia\"],\n",
    "    [\"herniation\", \"fistulation\"],\n",
    "    [\"hilar\", \"hyoid\", \"hilum\"],\n",
    "    [\n",
    "        \"hypertension\",\n",
    "        \"hypotension\",\n",
    "        \"hyperextension\",\n",
    "        \"hyperattenuation\",\n",
    "        \"hypoattenuation\",\n",
    "    ],\n",
    "    [\"indeterminant\", \"intermittent\"],\n",
    "    [\"inflammatory\", \"informatory\", \"inspiratory\"],\n",
    "    [\"intrapulmonary\", \"intraperitoneal\", \"intramedullary\", \"intravascular\"],\n",
    "    [\"lobular\", \"lobar\"],\n",
    "    [\"lymphangitis\", \"pancreatitis\", \"adenitis\"],\n",
    "    [\"lymphatic\", \"hepatic\"],\n",
    "    [\"marrow\", \"narrow\", \"macro\", \"micro\"],\n",
    "    [\"medullary\", \"modular\"],\n",
    "    [\"metastasis\", \"metaphysis\", \"metanalysis\", \"metastases\"],\n",
    "    [\"metastatic\", \"metaplastic\", \"myoclonic\", \"metabolic\", \"hyperplastic\"],\n",
    "    [\"millimetric\", \"metric\"],\n",
    "    [\"myocardial\", \"myocardium\", \"endocardial\", \"endocardium\", \"pericardium\"],\n",
    "    [\"nodule\", \"module\", \"tuber\"],\n",
    "    [\"non-specific\", \"non-systemic\", \"non-selective\"],\n",
    "    [\"occlusive\", \"conclusive\", \"inclusive\"],\n",
    "    [\"osteopenia\", \"sarcopenia\"],\n",
    "    [\"osteopenic\", \"osteoporotic\", \"osteolytic\", \"osteopathic\"],\n",
    "    [\"paratracheal\", \"paraoesophageal\", \"parabronchial\", \"pericardial\"],\n",
    "    [\"parenchyma\", \"pneumonia\"],\n",
    "    [\"pathological\", \"physiological\", \"psychological\"],\n",
    "    [\n",
    "        \"pericarditis\",\n",
    "        \"endocarditis\",\n",
    "        \"pleuritis\",\n",
    "        \"perichondritis\",\n",
    "        \"peritonitis\",\n",
    "        \"pneumonitis\",\n",
    "    ],\n",
    "    [\"perivascular\", \"perihilar\", \"peribronchial\"],\n",
    "    [\"plaque\", \"black\", \"plug\"],\n",
    "    [\"pneumothorax\", \"hemothorax\"],\n",
    "    [\"portal\", \"total\", \"pedal\"],\n",
    "    [\"previous\", \"pervious\", \"pylorus\"],\n",
    "    [\"pulmonary\", \"voluntary\"],\n",
    "    [\"reticular\", \"auricular\", \"trabecular\", \"vesicular\", \"articular\"],\n",
    "    [\n",
    "        \"reticulation\",\n",
    "        \"recirculation\",\n",
    "        \"recalculation\",\n",
    "        \"regulation\",\n",
    "        \"strangulation\",\n",
    "        \"ventilation\",\n",
    "        \"speculation\",\n",
    "        \"stipulation\",\n",
    "    ],\n",
    "    [\"retropulsion\", \"retroversion\", \"retroflexion\", \"reflexion\", \"expulsion\"],\n",
    "    [\"sequela\", \"sclera\", \"stella\"],\n",
    "    [\"sequelae\", \"sequestrae\"],\n",
    "    [\"significant\", \"malignant\", \"magnificant\", \"consistent\"],\n",
    "    [\"subphrenic\", \"subpleural\", \"subhepatic\", \"subdural\"],\n",
    "    [\"suspicious\", \"surreptitious\"],\n",
    "    [\"traction\", \"fraction\", \"action\", \"contraction\", \"reaction\"],\n",
    "    [\"vascular\", \"valvular\", \"muscular\", \"vestibular\", \"molecular\"],\n",
    "    [\"vocal\", \"focal\", \"vagal\", \"local\"],\n",
    "    [\"lymphadenopathy\", \"adenopathy\", \"radiculopathy\"],\n",
    "    [\"pleurodesis\", \"pleurocentesis\"],\n",
    "]\n",
    "\n",
    "omission = [\n",
    "    \"no\",\n",
    "    \"cannot\",\n",
    "    \"clear\",\n",
    "    \"clearly\",\n",
    "    \"exclude\",\n",
    "    \"excluded\",\n",
    "    \"increase\",\n",
    "    \"decrease\",\n",
    "    \"significant\",\n",
    "    \"more\",\n",
    "    \"greater\",\n",
    "    \"less\",\n",
    "]\n",
    "\n",
    "extraneous = [\n",
    "    \"the total\",\n",
    "    \"quina\",\n",
    "    \"management\",\n",
    "    \"office\",\n",
    "    \"staircase\",\n",
    "    \"hesitation\",\n",
    "    \"umbrella\",\n",
    "    \"keyboard\",\n",
    "    \"carriage\",\n",
    "]\n",
    "\n",
    "# Convert side confusion and near_homonym into dictionaries.\n",
    "sideConfusionDict = {}\n",
    "\n",
    "for mistakeWords in internalInconsistency:\n",
    "    for word in mistakeWords:\n",
    "        # Create a set from the mistake words\n",
    "        mistakeSet = set(mistakeWords)\n",
    "        wordSet = {word}\n",
    "        # print(f\"Current word = {wordSet} - {mistakeSet - wordSet}\")\n",
    "        sideConfusionDict[word] = mistakeSet - wordSet\n",
    "\n",
    "nearHomonymDict = {}\n",
    "\n",
    "for homonyms in transcription:\n",
    "    #   print(homonyms)\n",
    "    for currentHomonym in homonyms:\n",
    "        # print(currentHomonym)\n",
    "        closeHomonymSet = set(homonyms)\n",
    "        # print(f\"Current word = {currentHomonym} - {closeHomonymSet - {currentHomonym}}\")\n",
    "        nearHomonymDict[currentHomonym] = closeHomonymSet - {currentHomonym}\n",
    "\n",
    "# pprint(sideConfusionDict)\n",
    "# pprint(nearHomonymDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6705501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered by Omission:\n",
      " 14543    Clinical Information:\\npneumonia ?\\nTechnique:...\n",
      "2447     Clinical Information:\\npneumonia\\nTechnique:\\n...\n",
      "19135    Clinical Information:\\nSick pneumonia compatib...\n",
      "2839     Clinical Information:\\nbronchiectasis\\nTechniq...\n",
      "8296     Clinical Information:\\nWeakness, chills, shive...\n",
      "                               ...                        \n",
      "21290    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "3230     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "10758    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "3531     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "5048     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "Name: Correct Items, Length: 250, dtype: object\n",
      "Filtered by Internal Inconsistency:\n",
      " 6121     Clinical Information:\\nFall\\nTechnique:\\nNon-c...\n",
      "14699    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "3329     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "21598    Clinical Information:\\nBack pain\\nTechnique:\\n...\n",
      "6859     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "                               ...                        \n",
      "6490     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "14928    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "9826     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "14301    Clinical Information:\\ncough\\nTechnique:\\nNon-...\n",
      "11060    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "Name: Correct Items, Length: 250, dtype: object\n",
      "Filtered by Transcription Error:\n",
      " 19102    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "435      Clinical Information:\\nOperated right kidney t...\n",
      "4337     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "20866    Clinical Information:\\nOperated over ca\\nTechn...\n",
      "3305     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "                               ...                        \n",
      "10694    Clinical Information:\\nCough.\\nTechnique:\\nNon...\n",
      "23525    Clinical Information:\\nShortness of breath.\\nT...\n",
      "17409    Clinical Information:\\nweakened sense of smell...\n",
      "7718     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "17580    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "Name: Correct Items, Length: 250, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Look through the data and check whether we can add a sentence based on a containing word\n",
    "\n",
    "\n",
    "THRESHOLD = 250\n",
    "\n",
    "\n",
    "# Split a sentence by whitespace.\n",
    "def containingError(sent: str, itemSet: set) -> bool:\n",
    "    \"\"\"Boolean function that checks whether there is an intersection between key words of errors - used as a Boolean mask\"\"\"\n",
    "    sentList = set(sent.split())\n",
    "    if set(itemSet).intersection(sentList):\n",
    "        return True\n",
    "    return False\n",
    "    # Append to a set.\n",
    "\n",
    "\n",
    "los = [\n",
    "    (\"Omission\", omission),\n",
    "    (\"Internal Inconsistency\", set(sideConfusionDict.keys())),\n",
    "    (\"Transcription Error\", set(nearHomonymDict.keys())),\n",
    "]\n",
    "\n",
    "for name, itemSet in los:\n",
    "    filt = itemsToChange.apply(lambda row: containingError(row, itemSet))\n",
    "    filteredDF = itemsToChange[filt].sample(THRESHOLD, random_state=RANDOM_SEED)\n",
    "    print(f\"Filtered by {name}:\\n\", filteredDF)\n",
    "    # Remove items from itemsToChange\n",
    "    itemsToChange.drop(filteredDF.index, inplace=True)\n",
    "    filteredDF = filteredDF.to_frame(\"Original\")\n",
    "    filteredDF[\"Changed\"] = np.nan\n",
    "    filteredDF[\"ErrorType\"] = np.nan\n",
    "    filteredDF[\"ErrorExplanation\"] = np.nan\n",
    "    filteredDF[\"ErrorPhrases\"] = np.nan\n",
    "    filteredDF.to_csv(f\"datasets/training_{name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "555784f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered by errorFree:\n",
      " 19363    Clinical Information:\\nNon hodgkin lymphoma\\nT...\n",
      "12988    Clinical Information:\\npneumonia?\\nTechnique:\\...\n",
      "2441     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "20182    Clinical Information:\\npneumonia?\\nTechnique:\\...\n",
      "16756    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "                               ...                        \n",
      "2045     Clinical Information:\\nCovid parenchyma involv...\n",
      "19255    Clinical Information:\\ndyspnea\\nTechnique:\\nNo...\n",
      "19821    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "6371     Clinical Information:\\nCovid-19 pneumonia?\\nTe...\n",
      "17875    Clinical Information:\\nAML, evaluation before ...\n",
      "Name: Correct Items, Length: 250, dtype: object\n",
      "Filtered by Extraneous Statement:\n",
      " 20731    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "6666     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "15172    Clinical Information:\\nCovid-19 pneumonia\\nTec...\n",
      "21269    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "2335     Clinical Information:\\nFrequent urination, lef...\n",
      "                               ...                        \n",
      "16077    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "8513     Clinical Information:\\nCough.\\nTechnique:\\n1.5...\n",
      "13519    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "15969    Clinical Information:\\nOperated breast ca, con...\n",
      "20226    Clinical Information:\\nNodule?\\nTechnique:\\nSe...\n",
      "Name: Correct Items, Length: 250, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22445,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toAnnotate = [\"errorFree\", \"Extraneous Statement\"]\n",
    "# These need to be hand-annotated as they may be harder to computationally add.\n",
    "\n",
    "for error in toAnnotate:\n",
    "    filteredDF = itemsToChange.sample(THRESHOLD, random_state=RANDOM_SEED)\n",
    "    print(f\"Filtered by {error}:\\n\", filteredDF)\n",
    "    filteredDF = filteredDF.to_frame(\"Original\")\n",
    "    # Remove items from itemsToChange\n",
    "    itemsToChange.drop(filteredDF.index, inplace=True)\n",
    "    filteredDF[\"Changed\"] = np.nan\n",
    "    filteredDF[\"ErrorType\"] = np.nan\n",
    "    filteredDF[\"ErrorExplanation\"] = np.nan\n",
    "    filteredDF[\"ErrorPhrases\"] = np.nan\n",
    "    filteredDF.to_csv(f\"datasets/training_{error}.csv\")\n",
    "itemsToChange.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61b2d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErrorInjector:\n",
    "    \"\"\"A class to perform synthetic error injection.\"\"\"\n",
    "\n",
    "    def __init__(self, errorType: ErrorType):\n",
    "        self.errorType = errorType\n",
    "        if self.errorType == ErrorType.InternalInconsistency:\n",
    "            self.wordSet = set(sideConfusionDict.keys())\n",
    "            self.wordDict = sideConfusionDict\n",
    "        elif self.errorType == ErrorType.TranscriptionError:\n",
    "            self.wordSet = set(nearHomonymDict.keys())\n",
    "            self.wordDict = nearHomonymDict\n",
    "        elif self.errorType == ErrorType.Omission:\n",
    "            self.wordSet = set(omission)\n",
    "        else:\n",
    "            self.wordSet = None\n",
    "            self.wordDict = None\n",
    "\n",
    "    def reportCorrection(\n",
    "        self, report: str\n",
    "    ) -> tuple[ErrorType, list[str], list[str], str]:\n",
    "        \"\"\"Go through each sentence and check if there is a keyword, by turning it into a set. Use the intersection between the set + the sentence. Check whether each sentence in the dataset is correct.\"\"\"\n",
    "        tokenised = nltk.sent_tokenize(report)\n",
    "        for index, sentence in enumerate(tokenised):\n",
    "            intersect = self.wordSet.intersection(set(sentence.split(\" \")))\n",
    "            if len(intersect) > 0:\n",
    "                # Take the first element of the sentence and use the replace function to find the replacement word.\n",
    "                word = random.choice(list(intersect))\n",
    "                if self.errorType != ErrorType.Omission:\n",
    "                    # If the error type has word lists then choose a random thing.\n",
    "                    replacementList = list(self.wordDict[word])\n",
    "                    replace = random.choice(replacementList)\n",
    "                    newSentence = sentence.replace(word, replace, 1)\n",
    "                else:\n",
    "                    newSentence = sentence.replace(word, \"\", 1)\n",
    "                # print(f\"Old sentence = {sentence}\\nNew sentence = {newSentence}\")\n",
    "                tokenised[index] = newSentence\n",
    "                break\n",
    "        if self.errorType == ErrorType.Omission:\n",
    "            reason = f\"The word {word} was omitted.\"\n",
    "        elif self.errorType == ErrorType.InternalInconsistency:\n",
    "            reason = (\n",
    "                f\"There is an internal inconsistency, as {replace} should be {word}.\"\n",
    "            )\n",
    "        elif self.errorType == ErrorType.TranscriptionError:\n",
    "            reason = f\"There is a transcription error; {replace} should be written as {word}.\"\n",
    "        else:\n",
    "            raise Exception(\"There was an error in the ErrorType inputted.\")\n",
    "        newError = RadiologyError(\n",
    "            errorType=self.errorType,\n",
    "            errorPhrases=[newSentence],\n",
    "            errorExplanation=[reason],\n",
    "        )\n",
    "        return (\n",
    "            newError.errorType,\n",
    "            newError.errorPhrases,\n",
    "            newError.errorExplanation,\n",
    "            twd.detokenize(tokenised),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "37a9ae24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     Original  \\\n",
      "Unnamed: 0                                                      \n",
      "6121        Clinical Information:\\nFall\\nTechnique:\\nNon-c...   \n",
      "14699       Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "3329        Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "21598       Clinical Information:\\nBack pain\\nTechnique:\\n...   \n",
      "6859        Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "...                                                       ...   \n",
      "6490        Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "14928       Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "9826        Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "14301       Clinical Information:\\ncough\\nTechnique:\\nNon-...   \n",
      "11060       Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "\n",
      "                                                      Changed  \\\n",
      "Unnamed: 0                                                      \n",
      "6121        Clinical Information:\\nFall\\nTechnique:\\nNon-c...   \n",
      "14699       Clinical Information:\\nNot given. Technique:\\n...   \n",
      "3329        Clinical Information:\\nNot given. Technique:\\n...   \n",
      "21598       Clinical Information:\\nBack pain\\nTechnique:\\n...   \n",
      "6859        Clinical Information:\\nNot given. Technique:\\n...   \n",
      "...                                                       ...   \n",
      "6490        Clinical Information:\\nNot given. Technique:\\n...   \n",
      "14928       Clinical Information:\\nNot given. Technique:\\n...   \n",
      "9826        Clinical Information:\\nNot given. Technique:\\n...   \n",
      "14301       Clinical Information:\\ncough\\nTechnique:\\nNon-...   \n",
      "11060       Clinical Information:\\nNot given. Technique:\\n...   \n",
      "\n",
      "                         ErrorType  \\\n",
      "Unnamed: 0                           \n",
      "6121        Internal Inconsistency   \n",
      "14699       Internal Inconsistency   \n",
      "3329        Internal Inconsistency   \n",
      "21598       Internal Inconsistency   \n",
      "6859        Internal Inconsistency   \n",
      "...                            ...   \n",
      "6490        Internal Inconsistency   \n",
      "14928       Internal Inconsistency   \n",
      "9826        Internal Inconsistency   \n",
      "14301       Internal Inconsistency   \n",
      "11060       Internal Inconsistency   \n",
      "\n",
      "                                             ErrorExplanation  \\\n",
      "Unnamed: 0                                                      \n",
      "6121        There is an internal inconsistency, as lower s...   \n",
      "14699       There is an internal inconsistency, as upper s...   \n",
      "3329        There is an internal inconsistency, as upper s...   \n",
      "21598       There is an internal inconsistency, as decreas...   \n",
      "6859        There is an internal inconsistency, as lower s...   \n",
      "...                                                       ...   \n",
      "6490        There is an internal inconsistency, as lower s...   \n",
      "14928       There is an internal inconsistency, as anterio...   \n",
      "9826        There is an internal inconsistency, as central...   \n",
      "14301       There is an internal inconsistency, as lower s...   \n",
      "11060       There is an internal inconsistency, as upper s...   \n",
      "\n",
      "                                                 ErrorPhrases  \n",
      "Unnamed: 0                                                     \n",
      "6121        As far as can be seen within the sections; low...  \n",
      "14699       A 13 mm diameter parenchymal air cyst was obse...  \n",
      "3329        Sliding type hiatal hernia was observed at the...  \n",
      "21598       No pathological wall thickness decrease was ob...  \n",
      "6859        Cylindrical bronchiectasis, loss of volume and...  \n",
      "...                                                       ...  \n",
      "6490        There are emphysematous changes in the anterio...  \n",
      "14928       When examined in the lung parenchyma window; P...  \n",
      "9826        When examined in the lung parenchyma window; N...  \n",
      "14301       In the lower lobe of the right lung, nonspecif...  \n",
      "11060       In the right lung, nodules with a diameter of ...  \n",
      "\n",
      "[250 rows x 5 columns]\n",
      "                                                     Original  \\\n",
      "Unnamed: 0                                                      \n",
      "14543       Clinical Information:\\npneumonia ?\\nTechnique:...   \n",
      "2447        Clinical Information:\\npneumonia\\nTechnique:\\n...   \n",
      "19135       Clinical Information:\\nSick pneumonia compatib...   \n",
      "2839        Clinical Information:\\nbronchiectasis\\nTechniq...   \n",
      "8296        Clinical Information:\\nWeakness, chills, shive...   \n",
      "...                                                       ...   \n",
      "21290       Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "3230        Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "10758       Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "3531        Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "5048        Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "\n",
      "                                                      Changed ErrorType  \\\n",
      "Unnamed: 0                                                                \n",
      "14543       Clinical Information:\\npneumonia? Technique:\\n...  Omission   \n",
      "2447        Clinical Information:\\npneumonia\\nTechnique:\\n...  Omission   \n",
      "19135       Clinical Information:\\nSick pneumonia compatib...  Omission   \n",
      "2839        Clinical Information:\\nbronchiectasis\\nTechniq...  Omission   \n",
      "8296        Clinical Information:\\nWeakness, chills, shive...  Omission   \n",
      "...                                                       ...       ...   \n",
      "21290       Clinical Information:\\nNot given. Technique:\\n...  Omission   \n",
      "3230        Clinical Information:\\nNot given. Technique:\\n...  Omission   \n",
      "10758       Clinical Information:\\nNot given. Technique:\\n...  Omission   \n",
      "3531        Clinical Information:\\nNot given. Technique:\\n...  Omission   \n",
      "5048        Clinical Information:\\nNot given. Technique:\\n...  Omission   \n",
      "\n",
      "                             ErrorExplanation  \\\n",
      "Unnamed: 0                                      \n",
      "14543            The word cannot was omitted.   \n",
      "2447                 The word no was omitted.   \n",
      "19135       The word significant was omitted.   \n",
      "2839           The word increase was omitted.   \n",
      "8296             The word cannot was omitted.   \n",
      "...                                       ...   \n",
      "21290       The word significant was omitted.   \n",
      "3230                 The word no was omitted.   \n",
      "10758                The word no was omitted.   \n",
      "3531                 The word no was omitted.   \n",
      "5048                 The word no was omitted.   \n",
      "\n",
      "                                                 ErrorPhrases  \n",
      "Unnamed: 0                                                     \n",
      "14543       Mediastinal structures  be evaluated optimally...  \n",
      "2447        Trachea, both main bronchi are open and  occlu...  \n",
      "19135       Thoracic esophagus calibration was normal and ...  \n",
      "2839        No pathological  in wall thickness was observe...  \n",
      "8296        Mediastinal structures  be evaluated optimally...  \n",
      "...                                                       ...  \n",
      "21290       Thoracic esophagus calibration was normal and ...  \n",
      "3230        As far as can be observed,  mediastinal and bi...  \n",
      "10758       Thoracic esophageal calibration was rmal and n...  \n",
      "3531        Findings:\\nTrachea was in the midline of both ...  \n",
      "5048        Thoracic esophagus calibration was rmal and no...  \n",
      "\n",
      "[250 rows x 5 columns]\n",
      "                                                     Original  \\\n",
      "Unnamed: 0                                                      \n",
      "19102       Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "435         Clinical Information:\\nOperated right kidney t...   \n",
      "4337        Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "20866       Clinical Information:\\nOperated over ca\\nTechn...   \n",
      "3305        Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "...                                                       ...   \n",
      "10694       Clinical Information:\\nCough.\\nTechnique:\\nNon...   \n",
      "23525       Clinical Information:\\nShortness of breath.\\nT...   \n",
      "17409       Clinical Information:\\nweakened sense of smell...   \n",
      "7718        Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "17580       Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "\n",
      "                                                      Changed  \\\n",
      "Unnamed: 0                                                      \n",
      "19102       Clinical Information:\\nNot given. Technique:\\n...   \n",
      "435         Clinical Information:\\nOperated right kidney t...   \n",
      "4337        Clinical Information:\\nNot given. Technique:\\n...   \n",
      "20866       Clinical Information:\\nOperated over ca\\nTechn...   \n",
      "3305        Clinical Information:\\nNot given. Technique:\\n...   \n",
      "...                                                       ...   \n",
      "10694       Clinical Information:\\nCough. Technique:\\nNon-...   \n",
      "23525       Clinical Information:\\nShortness of breath. Te...   \n",
      "17409       Clinical Information:\\nweakened sense of smell...   \n",
      "7718        Clinical Information:\\nNot given. Technique:\\n...   \n",
      "17580       Clinical Information:\\nNot given. Technique:\\n...   \n",
      "\n",
      "                      ErrorType  \\\n",
      "Unnamed: 0                        \n",
      "19102       Transcription Error   \n",
      "435         Transcription Error   \n",
      "4337        Transcription Error   \n",
      "20866       Transcription Error   \n",
      "3305        Transcription Error   \n",
      "...                         ...   \n",
      "10694       Transcription Error   \n",
      "23525       Transcription Error   \n",
      "17409       Transcription Error   \n",
      "7718        Transcription Error   \n",
      "17580       Transcription Error   \n",
      "\n",
      "                                             ErrorExplanation  \\\n",
      "Unnamed: 0                                                      \n",
      "19102       There is a transcription error; physiological ...   \n",
      "435         There is a transcription error; bronchiectasis...   \n",
      "4337        There is a transcription error; bronchiolitis ...   \n",
      "20866       There is a transcription error; psychological ...   \n",
      "3305        There is a transcription error; bronchiectasis...   \n",
      "...                                                       ...   \n",
      "10694       There is a transcription error; bronchiolitis ...   \n",
      "23525       There is a transcription error; bronchiectasis...   \n",
      "17409       There is a transcription error; cm should be w...   \n",
      "7718        There is a transcription error; bronchiolitis ...   \n",
      "17580       There is a transcription error; consolidative ...   \n",
      "\n",
      "                                                 ErrorPhrases  \n",
      "Unnamed: 0                                                     \n",
      "19102       Findings:\\nIn the section, no lymph node in ph...  \n",
      "435               Trachea, both main bronchiectasis are open.  \n",
      "4337                        Both main bronchiolitis are open.  \n",
      "20866       Findings:\\nNo lymph node was observed in the s...  \n",
      "3305        Findings:\\nTrachea, both main bronchiectasis a...  \n",
      "...                                                       ...  \n",
      "10694       Findings:\\nTrachea, both main bronchiolitis ar...  \n",
      "23525       Findings:\\nTrachea and both main bronchiectasi...  \n",
      "17409       Clinical Information:\\nweakened sense of smell...  \n",
      "7718        Findings:\\nTrachea, both main bronchiolitis ar...  \n",
      "17580       Findings:\\nTrachea and both main bronchi were ...  \n",
      "\n",
      "[250 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "def addError(path: str, errorType: ErrorType):\n",
    "    \"\"\"Add the errors into the csv.\"\"\"\n",
    "    errorDataset = pd.read_csv(path, index_col=0)\n",
    "\n",
    "    dataToChange = errorDataset[\"Original\"]\n",
    "\n",
    "    iiError = ErrorInjector(errorType=errorType)\n",
    "    temp = dataToChange.apply(lambda s: iiError.reportCorrection(s))\n",
    "    errorDataset[\"ErrorType\"] = temp.apply(lambda e: e[0].value)\n",
    "    errorDataset[\"ErrorPhrases\"] = temp.apply(lambda e: \";\".join(e[1]))\n",
    "    errorDataset[\"ErrorExplanation\"] = temp.apply(lambda e: \";\".join(e[2]))\n",
    "    errorDataset[\"Changed\"] = temp.apply(lambda e: e[3])\n",
    "    print(errorDataset)\n",
    "    errorDataset.to_csv(path)\n",
    "\n",
    "\n",
    "addError(\n",
    "    \"datasets/training_Internal Inconsistency.csv\", ErrorType.InternalInconsistency\n",
    ")\n",
    "addError(\"datasets/training_Omission.csv\", ErrorType.Omission)\n",
    "addError(\"datasets/training_Transcription Error.csv\", ErrorType.TranscriptionError)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22f509c",
   "metadata": {},
   "source": [
    "# Reconstituting the dataset back together.\n",
    "\n",
    "Running this code requires that the extraneous statement set of data are annotated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b80b17d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/training_Internal Inconsistency.csv: (250, 5)\n",
      "datasets/training_Transcription Error.csv: (250, 5)\n",
      "datasets/training_Extraneous Statement_annotated.csv: (250, 5)\n",
      "datasets/training_Omission.csv: (250, 7)\n",
      "Index(['Original', 'Changed', 'ErrorType', 'ErrorExplanation', 'ErrorPhrases',\n",
      "       'Unnamed: 0', 'YZ Comment'],\n",
      "      dtype='object')\n",
      "                                              Original  \\\n",
      "0    Clinical Information:\\ncovid?\\nTechnique:\\nNon...   \n",
      "1    Clinical Information:\\n chest pain\\nTechnique:...   \n",
      "2    Clinical Information:\\nKidney transplant 20 da...   \n",
      "3    Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "4    Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "..                                                 ...   \n",
      "995  Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "996  Clinical Information:\\nThroat and headache\\nTe...   \n",
      "997  Clinical Information:\\nnot given\\nTechnique:\\n...   \n",
      "998  Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "999  Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "\n",
      "                                               Changed ErrorType  \\\n",
      "0    Clinical Information:\\ncovid?\\nTechnique:\\nNon...      None   \n",
      "1    Clinical Information:\\n chest pain\\nTechnique:...      None   \n",
      "2    Clinical Information:\\nKidney transplant 20 da...      None   \n",
      "3    Clinical Information:\\nNot given.\\nTechnique:\\...      None   \n",
      "4    Clinical Information:\\nNot given.\\nTechnique:\\...      None   \n",
      "..                                                 ...       ...   \n",
      "995  Clinical Information:\\nNot given. Technique:\\n...  Omission   \n",
      "996  Clinical Information:\\nThroat and headache\\nTe...  Omission   \n",
      "997  Clinical Information:\\nnot given\\nTechnique:\\n...  Omission   \n",
      "998  Clinical Information:\\nNot given. Technique:\\n...  Omission   \n",
      "999  Clinical Information:\\nNot given. Technique:\\n...  Omission   \n",
      "\n",
      "                          ErrorExplanation  \\\n",
      "0                                     None   \n",
      "1                                     None   \n",
      "2                                     None   \n",
      "3                                     None   \n",
      "4                                     None   \n",
      "..                                     ...   \n",
      "995  ['The word significant was omitted.']   \n",
      "996  ['The word significant was omitted.']   \n",
      "997           ['The word no was omitted.']   \n",
      "998  ['The word significant was omitted.']   \n",
      "999           ['The word no was omitted.']   \n",
      "\n",
      "                                          ErrorPhrases  Unnamed: 0 YZ Comment  \\\n",
      "0                                                 None         NaN        NaN   \n",
      "1                                                 None         NaN        NaN   \n",
      "2                                                 None         NaN        NaN   \n",
      "3                                                 None         NaN        NaN   \n",
      "4                                                 None         NaN        NaN   \n",
      "..                                                 ...         ...        ...   \n",
      "995  ['Enlarged lymph nodes in prevascular, pre-par...     15854.0        NaN   \n",
      "996  ['Thoracic esophageal calibration was normal a...     16540.0        NaN   \n",
      "997  ['Ventilation of both lungs is rmal and no mas...     15682.0        NaN   \n",
      "998  ['Thoracic esophageal calibration was normal a...      5758.0        NaN   \n",
      "999  ['Lytic-destructive lesion was detected in bon...      2581.0        NaN   \n",
      "\n",
      "                                                 input  \\\n",
      "0    Clinical Information:\\ncovid?\\nTechnique:\\nNon...   \n",
      "1    Clinical Information:\\n chest pain\\nTechnique:...   \n",
      "2    Clinical Information:\\nKidney transplant 20 da...   \n",
      "3    Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "4    Clinical Information:\\nNot given.\\nTechnique:\\...   \n",
      "..                                                 ...   \n",
      "995  Clinical Information:\\nNot given. Technique:\\n...   \n",
      "996  Clinical Information:\\nThroat and headache\\nTe...   \n",
      "997  Clinical Information:\\nnot given\\nTechnique:\\n...   \n",
      "998  Clinical Information:\\nNot given. Technique:\\n...   \n",
      "999  Clinical Information:\\nNot given. Technique:\\n...   \n",
      "\n",
      "                                                output  \n",
      "0                                                   {}  \n",
      "1                                                   {}  \n",
      "2                                                   {}  \n",
      "3                                                   {}  \n",
      "4                                                   {}  \n",
      "..                                                 ...  \n",
      "995  {\"errorsForWholeText\":[{\"errorType\":\"Omission\"...  \n",
      "996  {\"errorsForWholeText\":[{\"errorType\":\"Omission\"...  \n",
      "997  {\"errorsForWholeText\":[{\"errorType\":\"Omission\"...  \n",
      "998  {\"errorsForWholeText\":[{\"errorType\":\"Omission\"...  \n",
      "999  {\"errorsForWholeText\":[{\"errorType\":\"Omission\"...  \n",
      "\n",
      "[1000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Collate all errors into one document.\n",
    "\n",
    "datasetPaths = [\n",
    "    \"datasets/training_Internal Inconsistency.csv\",\n",
    "    \"datasets/training_Transcription Error.csv\",\n",
    "    \"datasets/training_Extraneous Statement_annotated.csv\",\n",
    "    \"datasets/training_Omission.csv\",\n",
    "]\n",
    "trainSet = []\n",
    "testSet = []\n",
    "\n",
    "# Fix the error free data - move everything to corrected\n",
    "\n",
    "EFData = pd.read_csv(\"datasets/training_errorFree_annotated.csv\", index_col=0)\n",
    "\n",
    "EFData[\"Changed\"] = EFData[\"Changed\"].fillna(EFData[\"Original\"])\n",
    "EFData[\"ErrorType\"] = EFData[\"ErrorType\"].fillna(\"None\")\n",
    "EFData[\"ErrorPhrases\"] = EFData[\"ErrorPhrases\"].fillna(\"None\")\n",
    "EFData[\"ErrorExplanation\"] = EFData[\"ErrorExplanation\"].fillna(\"None\")\n",
    "\n",
    "trainEF = EFData.sample(frac=0.8, random_state=RANDOM_SEED)\n",
    "testEF = EFData.drop(trainEF.index)\n",
    "trainSet.append(trainEF)\n",
    "testSet.append(testEF)\n",
    "\n",
    "# print(EFData[\"Changed\"])\n",
    "\n",
    "\n",
    "for dp in datasetPaths:\n",
    "    ds = pd.read_csv(dp, index_col=0)\n",
    "    print(f\"{dp}: {ds.shape}\")\n",
    "    train = ds.sample(frac=0.8, random_state=RANDOM_SEED)\n",
    "    test = ds.drop(train.index)\n",
    "    trainSet.append(train)\n",
    "    testSet.append(test)\n",
    "    # print(ds[\"Changed\"])\n",
    "trainDF = pd.concat(trainSet, ignore_index=True)\n",
    "testDF = pd.concat(testSet, ignore_index=True)\n",
    "# print(trainDF.shape)\n",
    "# print(testDF.shape)\n",
    "print(trainDF.columns)\n",
    "# print(testDF.columns)\n",
    "\n",
    "\n",
    "# Create input and output labels.\n",
    "def createOutput(row):\n",
    "    \"\"\"Return the radiology error list in JSON.\"\"\"\n",
    "    radErr: RadiologyErrors = []\n",
    "    tempType: str = row[\"ErrorType\"]\n",
    "    tempPhrases: str = row[\"ErrorPhrases\"]\n",
    "    tempExplanation: str = row[\"ErrorExplanation\"]\n",
    "    # print(tempExplanation)\n",
    "    # TODO fix this error.\n",
    "    # if type(tempPhrases) is float:\n",
    "    #     raise Exception(f\"{tempPhrases}, {tempExplanation}\")\n",
    "    if tempType != \"None\" and type(tempPhrases) is not float:\n",
    "        radErr.append(\n",
    "            RadiologyError(\n",
    "                errorType=ErrorType(tempType),\n",
    "                errorPhrases=tempPhrases.split(\";\"),\n",
    "                errorExplanation=tempExplanation.split(\";\"),\n",
    "            )\n",
    "        )\n",
    "        return RadiologyErrors(errorsForWholeText=radErr).model_dump_json()\n",
    "    else:\n",
    "        return \"{}\"\n",
    "\n",
    "\n",
    "trainDF[\"input\"] = trainDF[\"Changed\"]\n",
    "# print(trainDF)\n",
    "trainDF[\"output\"] = trainDF.apply(lambda s: createOutput(s), axis=1)\n",
    "testDF[\"input\"] = testDF[\"Changed\"]\n",
    "print(trainDF)\n",
    "testDF[\"output\"] = testDF.apply(lambda s: createOutput(s), axis=1)\n",
    "\n",
    "trainDF[[\"input\", \"output\"]].to_csv(\"datasets/finetuning_train.csv\")\n",
    "testDF[[\"input\", \"output\"]].to_csv(\"datasets/finetuning_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbc9f2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/harrykeeran12/ctrate_injected_errors/commit/97f792e4aa86108cf6ca8f112334d782693a0800', commit_message='Uploading testing set.', commit_description='', oid='97f792e4aa86108cf6ca8f112334d782693a0800', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/harrykeeran12/ctrate_injected_errors', endpoint='https://huggingface.co', repo_type='dataset', repo_id='harrykeeran12/ctrate_injected_errors'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import huggingface_hub\n",
    "load_dotenv()\n",
    "\n",
    "repository = \"harrykeeran12/ctrate_injected_errors\"\n",
    "huggingface_hub.upload_file(\n",
    "    repo_id=repository,\n",
    "    path_or_fileobj=\"datasets/finetuning_train.csv\",\n",
    "    commit_message=\"Uploading training set.\",\n",
    "    path_in_repo=\"finetuning_train.csv\",\n",
    "    repo_type=\"dataset\",\n",
    ")\n",
    "huggingface_hub.upload_file(\n",
    "    repo_id=repository,\n",
    "    path_or_fileobj=\"datasets/finetuning_test.csv\",\n",
    "    commit_message=\"Uploading testing set.\",\n",
    "    path_in_repo=\"finetuning_test.csv\",\n",
    "    repo_type=\"dataset\"\n",
    ")\n",
    "# huggingface_hub.login()\n",
    "# train = load_dataset(\"csv\", data_files=\"datasets/finetuning_train.csv\")\n",
    "# test = load_dataset(\"csv\", data_files=\"datasets/finetuning_test.csv\")\n",
    "\n",
    "# train.push_to_hub(\"\")\n",
    "# test.push_to_hub(\"harrykeeran12/ctrate_injected_errors\")\n",
    "# , token=os.getenv(\"HF_TOKEN\"))\n",
    "# test.push_to_hub(\"harrykeeran12/ctrate_injected_errors\", token=os.getenv(\"HF_TOKEN\"))\n",
    "# train.push_to_hub(\"harrykeeran12/ctrate_injected_errors\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hons",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
