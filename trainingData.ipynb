{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e51804ce",
   "metadata": {},
   "source": [
    "# Analysing the training data:\n",
    "\n",
    "The training data was taken from the CT-RATE reports.\n",
    "We can create synthetic data by finding which items we can change.\n",
    "\n",
    "We want a set of items that is just error-free. This must be analysed to check whether they are error-free or not, or maybe modified such that they are error-free. \n",
    "\n",
    "We also want 4 datasets that contain errors. These errors are internal inconsistencies, extraneous statements, transcription errors and omissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6595f000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current number of data to change: 23695\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import nltk\n",
    "import random\n",
    "from schema import RadiologyErrors, RadiologyError, ErrorType\n",
    "\n",
    "df = pd.read_csv(\"datasets/training_data1.csv\")\n",
    "\n",
    "itemsToChange = df[\"Correct Items\"]\n",
    "\n",
    "print(f\"Current number of data to change: {len(itemsToChange)}\")\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "adb11894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what words can be used to find errors:\n",
    "\n",
    "internalInconsistency = [\n",
    "    [\"anterior\", \"posterior\"],\n",
    "    [\"medial\", \"lateral\"],\n",
    "    [\"superior\", \"inferior\"],\n",
    "    [\n",
    "        \"anterolateral\",\n",
    "        \"posterolateral\",\n",
    "        \"supralateral\",\n",
    "        \"infralateral\",\n",
    "        \"anterosuperior\",\n",
    "        \"posterosuperior\",\n",
    "        \"anteroposterior\",\n",
    "    ],\n",
    "    [\n",
    "        \"anteromedial\",\n",
    "        \"posteromedial\",\n",
    "        \"supramedial\",\n",
    "        \"inframedial\",\n",
    "        \"anteroinferior\",\n",
    "        \"posteroinferior\",\n",
    "        \"posteroanterior\",\n",
    "    ],\n",
    "    [\n",
    "        \"anterior-lateral\",\n",
    "        \"posterior-lateral\",\n",
    "        \"superior-lateral\",\n",
    "        \"inferior-lateral\",\n",
    "        \"anterior-superior\",\n",
    "        \"posterior-superior\",\n",
    "    ],\n",
    "    [\n",
    "        \"anterior-medial\",\n",
    "        \"posterior-medial\",\n",
    "        \"superior-medial\",\n",
    "        \"inferior-medial\",\n",
    "        \"anterior-inferior\",\n",
    "        \"posterior-inferior\",\n",
    "    ],\n",
    "    [\"anterior-posterior\", \"medial-lateral\", \"superior-inferior\"],\n",
    "    [\"dorsal-ventral\", \"transverse\", \"craniocaudal\"],\n",
    "    [\"cranial\", \"caudal\"],\n",
    "    [\"hepatopedal\", \"hepatofugal\"],\n",
    "    [\"dorsal\", \"ventral\"],\n",
    "    [\"proximal\", \"distal\"],\n",
    "    [\"long axis\", \"short axis\"],\n",
    "    [\"peripheral\", \"central\"],\n",
    "    [\"superficial\", \"deep\"],\n",
    "    [\"metaphysis\", \"diaphysis\", \"epiphysis\"],\n",
    "    [\"ascending\", \"descending\"],\n",
    "    [\"increase\", \"decrease\"],\n",
    "    [\"increased\", \"decreased\"],\n",
    "    [\"basal\", \"apical\"],\n",
    "    [\"hyperdense\", \"hypodense\"],\n",
    "    [\"solid\", \"cystic\"],\n",
    "    [\"dependent\", \"non-dependent\"],\n",
    "    [\"upper\", \"lower\"],\n",
    "]\n",
    "\n",
    "transcription = [\n",
    "    [\"abscess\", \"access\", \"assess\"],\n",
    "    [\"achalasia\", \"atelectasis\", \"epistaxis\"],\n",
    "    [\"adrenal\", \"renal\"],\n",
    "    [\"alveolar\", \"valcular\", \"lobular\", \"tubular\"],\n",
    "    [\"aneurysm\", \"anaplasia\", \"anemia\"],\n",
    "    [\"anterolisthesis\", \"retrolisthesis\", \"spondylolisthesis\"],\n",
    "    [\"ascites\", \"cystitis\", \"bursitis\", \"colitic\"],\n",
    "    [\"aspiration\", \"eventration\"],\n",
    "    [\"atheroma\", \"myxoma\", \"osteoma\", \"lipoma\"],\n",
    "    [\"borderline\", \"baseline\"],\n",
    "    [\"bronchiectasis\", \"bronchitis\", \"bronchiolitis\", \"bronchi\"],\n",
    "    [\"bronchogenic\", \"bronchiolitic\", \"bronchoscopic\"],\n",
    "    [\"bullous\", \"mucous\"],\n",
    "    [\"calcified\", \"ossified\", \"classified\"],\n",
    "    [\"carcinomatosis,sarcomatosis\", \"carcinosis\", \"sarcoidosis\"],\n",
    "    [\"cm\", \"mm\", \"m\"],\n",
    "    [\"consolidation\", \"accumulation\", \"congestion\", \"compaction\", \"obstruction\"],\n",
    "    [\"consolidative\", \"accumulative\", \"congestive\", \"obstructive\"],\n",
    "    [\"coronary\", \"coronal\", \"coronoid\", \"coracoid\", \"corneal\"],\n",
    "    [\"corpuscles\", \"corpus\", \"corvus\", \"corpse\"],\n",
    "    [\"cortical\", \"corticoid\", \"corticate\"],\n",
    "    [\"craniocaudal\", \"craniocervical\", \"craniobasal\"],\n",
    "    [\"cyst\", \"gist\", \"list\", \"fist\"],\n",
    "    [\"cystic\", \"systolic\", \"caustic\", \"cyclic\", \"plastic\"],\n",
    "    [\"degenerative\", \"regenerative\", \"destructive\"],\n",
    "    [\"diaphragm\", \"diagram\", \"diaphysis\"],\n",
    "    [\"edematous\", \"erythematous\", \"emphysematous\"],\n",
    "    [\"effusion\", \"confusion\", \"diffusion\", \"perfusion\", \"occlusion\"],\n",
    "    [\"empyema\", \"emphysema\", \"haematoma\", \"endothelium\"],\n",
    "    [\"endobronchial\", \"endotracheal\"],\n",
    "    [\"esophagogastric\", \"esophagocolic\"],\n",
    "    [\"esophagus\", \"esophagitis\"],\n",
    "    [\n",
    "        \"fibrosis\",\n",
    "        \"stenosis\",\n",
    "        \"sclerosis\",\n",
    "        \"synostosis\",\n",
    "        \"cyanosis\",\n",
    "        \"thrombosis\",\n",
    "        \"necrosis\",\n",
    "        \"nephrosis\",\n",
    "        \"silicosis\",\n",
    "        \"cirrhosis\",\n",
    "        \"asbestosis\",\n",
    "        \"aspergillosis\",\n",
    "        \"kyphosis\",\n",
    "        \"lordosis\",\n",
    "        \"mycosis\",\n",
    "    ],\n",
    "    [\n",
    "        \"fibrotic\",\n",
    "        \"stenotic\",\n",
    "        \"sclerotic\",\n",
    "        \"cyanotic\",\n",
    "        \"thrombotic\",\n",
    "        \"necrotic\",\n",
    "        \"nephrotic\",\n",
    "        \"cirrhotic\",\n",
    "    ],\n",
    "    [\"fissure\", \"fixture\", \"fisher\", \"fistula\", \"fossa\"],\n",
    "    [\"fluid\", \"flutter\", \"fluctuant\", \"florid\"],\n",
    "    [\"fracture\", \"friction\", \"contracture\", \"rapture\"],\n",
    "    [\"fusiform\", \"reniform\"],\n",
    "    [\"gastroesophageal\", \"gastroduodenal\", \"gastrojejunal\", \"gastroepiploic\"],\n",
    "    [\"ground glass/ground-glass\", \"ground grass\", \"brown glass\", \"brown brass\"],\n",
    "    [\"hemorrhagic\", \"hemostatic\", \"hemolytic\"],\n",
    "    [\"hernia\", \"fistula\", \"myalgia\"],\n",
    "    [\"herniation\", \"fistulation\"],\n",
    "    [\"hilar\", \"hyoid\", \"hilum\"],\n",
    "    [\n",
    "        \"hypertension\",\n",
    "        \"hypotension\",\n",
    "        \"hyperextension\",\n",
    "        \"hyperattenuation\",\n",
    "        \"hypoattenuation\",\n",
    "    ],\n",
    "    [\"indeterminant\", \"intermittent\"],\n",
    "    [\"inflammatory\", \"informatory\", \"inspiratory\"],\n",
    "    [\"intrapulmonary\", \"intraperitoneal\", \"intramedullary\", \"intravascular\"],\n",
    "    [\"lobular\", \"lobar\"],\n",
    "    [\"lymphangitis\", \"pancreatitis\", \"adenitis\"],\n",
    "    [\"lymphatic\", \"hepatic\"],\n",
    "    [\"marrow\", \"narrow\", \"macro\", \"micro\"],\n",
    "    [\"medullary\", \"modular\"],\n",
    "    [\"metastasis\", \"metaphysis\", \"metanalysis\", \"metastases\"],\n",
    "    [\"metastatic\", \"metaplastic\", \"myoclonic\", \"metabolic\", \"hyperplastic\"],\n",
    "    [\"millimetric\", \"metric\"],\n",
    "    [\"myocardial\", \"myocardium\", \"endocardial\", \"endocardium\", \"pericardium\"],\n",
    "    [\"nodule\", \"module\", \"tuber\"],\n",
    "    [\"non-specific\", \"non-systemic\", \"non-selective\"],\n",
    "    [\"occlusive\", \"conclusive\", \"inclusive\"],\n",
    "    [\"osteopenia\", \"sarcopenia\"],\n",
    "    [\"osteopenic\", \"osteoporotic\", \"osteolytic\", \"osteopathic\"],\n",
    "    [\"paratracheal\", \"paraoesophageal\", \"parabronchial\", \"pericardial\"],\n",
    "    [\"parenchyma\", \"pneumonia\"],\n",
    "    [\"pathological\", \"physiological\", \"psychological\"],\n",
    "    [\n",
    "        \"pericarditis\",\n",
    "        \"endocarditis\",\n",
    "        \"pleuritis\",\n",
    "        \"perichondritis\",\n",
    "        \"peritonitis\",\n",
    "        \"pneumonitis\",\n",
    "    ],\n",
    "    [\"perivascular\", \"perihilar\", \"peribronchial\"],\n",
    "    [\"plaque\", \"black\", \"plug\"],\n",
    "    [\"pneumothorax\", \"hemothorax\"],\n",
    "    [\"portal\", \"total\", \"pedal\"],\n",
    "    [\"previous\", \"pervious\", \"pylorus\"],\n",
    "    [\"pulmonary\", \"voluntary\"],\n",
    "    [\"reticular\", \"auricular\", \"trabecular\", \"vesicular\", \"articular\"],\n",
    "    [\n",
    "        \"reticulation\",\n",
    "        \"recirculation\",\n",
    "        \"recalculation\",\n",
    "        \"regulation\",\n",
    "        \"strangulation\",\n",
    "        \"ventilation\",\n",
    "        \"speculation\",\n",
    "        \"stipulation\",\n",
    "    ],\n",
    "    [\"retropulsion\", \"retroversion\", \"retroflexion\", \"reflexion\", \"expulsion\"],\n",
    "    [\"sequela\", \"sclera\", \"stella\"],\n",
    "    [\"sequelae\", \"sequestrae\"],\n",
    "    [\"significant\", \"malignant\", \"magnificant\", \"consistent\"],\n",
    "    [\"subphrenic\", \"subpleural\", \"subhepatic\", \"subdural\"],\n",
    "    [\"suspicious\", \"surreptitious\"],\n",
    "    [\"traction\", \"fraction\", \"action\", \"contraction\", \"reaction\"],\n",
    "    [\"vascular\", \"valvular\", \"muscular\", \"vestibular\", \"molecular\"],\n",
    "    [\"vocal\", \"focal\", \"vagal\", \"local\"],\n",
    "    [\"lymphadenopathy\", \"adenopathy\", \"radiculopathy\"],\n",
    "    [\"pleurodesis\", \"pleurocentesis\"],\n",
    "]\n",
    "\n",
    "omission = [\n",
    "    \"no\",\n",
    "    \"cannot\",\n",
    "    \"clear\",\n",
    "    \"clearly\",\n",
    "    \"exclude\",\n",
    "    \"excluded\",\n",
    "    \"increase\",\n",
    "    \"decrease\",\n",
    "    \"significant\",\n",
    "    \"more\",\n",
    "    \"greater\",\n",
    "    \"less\",\n",
    "]\n",
    "\n",
    "extraneous = [\n",
    "    \"the total\",\n",
    "    \"quina\",\n",
    "    \"management\",\n",
    "    \"office\",\n",
    "    \"staircase\",\n",
    "    \"hesitation\",\n",
    "    \"umbrella\",\n",
    "    \"keyboard\",\n",
    "    \"carriage\",\n",
    "]\n",
    "\n",
    "# Convert side confusion and near_homonym into dictionaries.\n",
    "sideConfusionDict = {}\n",
    "\n",
    "for mistakeWords in internalInconsistency:\n",
    "    for word in mistakeWords:\n",
    "        # Create a set from the mistake words\n",
    "        mistakeSet = set(mistakeWords)\n",
    "        wordSet = {word}\n",
    "        # print(f\"Current word = {wordSet} - {mistakeSet - wordSet}\")\n",
    "        sideConfusionDict[word] = mistakeSet - wordSet\n",
    "\n",
    "nearHomonymDict = {}\n",
    "\n",
    "for homonyms in transcription:\n",
    "    #   print(homonyms)\n",
    "    for currentHomonym in homonyms:\n",
    "        # print(currentHomonym)\n",
    "        closeHomonymSet = set(homonyms)\n",
    "        # print(f\"Current word = {currentHomonym} - {closeHomonymSet - {currentHomonym}}\")\n",
    "        nearHomonymDict[currentHomonym] = closeHomonymSet - {currentHomonym}\n",
    "\n",
    "# pprint(sideConfusionDict)\n",
    "# pprint(nearHomonymDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6705501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered by Omission:\n",
      " 14543    Clinical Information:\\npneumonia ?\\nTechnique:...\n",
      "2447     Clinical Information:\\npneumonia\\nTechnique:\\n...\n",
      "19135    Clinical Information:\\nSick pneumonia compatib...\n",
      "2839     Clinical Information:\\nbronchiectasis\\nTechniq...\n",
      "8296     Clinical Information:\\nWeakness, chills, shive...\n",
      "                               ...                        \n",
      "21290    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "3230     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "10758    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "3531     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "5048     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "Name: Correct Items, Length: 250, dtype: object\n",
      "Filtered by Internal Inconsistency:\n",
      " 6121     Clinical Information:\\nFall\\nTechnique:\\nNon-c...\n",
      "14699    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "3329     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "21598    Clinical Information:\\nBack pain\\nTechnique:\\n...\n",
      "6859     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "                               ...                        \n",
      "6490     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "14928    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "9826     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "14301    Clinical Information:\\ncough\\nTechnique:\\nNon-...\n",
      "11060    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "Name: Correct Items, Length: 250, dtype: object\n",
      "Filtered by Transcription Error:\n",
      " 19102    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "435      Clinical Information:\\nOperated right kidney t...\n",
      "4337     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "20866    Clinical Information:\\nOperated over ca\\nTechn...\n",
      "3305     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "                               ...                        \n",
      "10694    Clinical Information:\\nCough.\\nTechnique:\\nNon...\n",
      "23525    Clinical Information:\\nShortness of breath.\\nT...\n",
      "17409    Clinical Information:\\nweakened sense of smell...\n",
      "7718     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "17580    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "Name: Correct Items, Length: 250, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Look through the data and check whether we can add a sentence based on a containing word\n",
    "\n",
    "\n",
    "THRESHOLD = 250\n",
    "\n",
    "\n",
    "# Split a sentence by whitespace.\n",
    "def containingError(sent: str, itemSet: set) -> bool:\n",
    "    \"\"\"Boolean function that checks whether there is an intersection between key words of errors - used as a Boolean mask\"\"\"\n",
    "    sentList = set(sent.split())\n",
    "    if set(itemSet).intersection(sentList):\n",
    "        return True\n",
    "    return False\n",
    "    # Append to a set.\n",
    "\n",
    "\n",
    "los = [\n",
    "    (\"Omission\", omission),\n",
    "    (\"Internal Inconsistency\", set(sideConfusionDict.keys())),\n",
    "    (\"Transcription Error\", set(nearHomonymDict.keys())),\n",
    "]\n",
    "\n",
    "for name, itemSet in los:\n",
    "    filt = itemsToChange.apply(lambda row: containingError(row, itemSet))\n",
    "    filteredDF = itemsToChange[filt].sample(THRESHOLD, random_state=RANDOM_SEED)\n",
    "    print(f\"Filtered by {name}:\\n\", filteredDF)\n",
    "    # Remove items from itemsToChange\n",
    "    itemsToChange.drop(filteredDF.index, inplace=True)\n",
    "    filteredDF = filteredDF.to_frame(\"Original\")\n",
    "    filteredDF[\"Changed\"] = np.nan\n",
    "    filteredDF[\"ErrorType\"] = np.nan\n",
    "    filteredDF[\"ErrorExplanation\"] = np.nan\n",
    "    filteredDF[\"ErrorPhrases\"] = np.nan\n",
    "    filteredDF.to_csv(f\"datasets/training_{name}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "555784f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered by errorFree:\n",
      " 19363    Clinical Information:\\nNon hodgkin lymphoma\\nT...\n",
      "12988    Clinical Information:\\npneumonia?\\nTechnique:\\...\n",
      "2441     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "20182    Clinical Information:\\npneumonia?\\nTechnique:\\...\n",
      "16756    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "                               ...                        \n",
      "2045     Clinical Information:\\nCovid parenchyma involv...\n",
      "19255    Clinical Information:\\ndyspnea\\nTechnique:\\nNo...\n",
      "19821    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "6371     Clinical Information:\\nCovid-19 pneumonia?\\nTe...\n",
      "17875    Clinical Information:\\nAML, evaluation before ...\n",
      "Name: Correct Items, Length: 250, dtype: object\n",
      "Filtered by Extraneous Statement:\n",
      " 20731    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "6666     Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "15172    Clinical Information:\\nCovid-19 pneumonia\\nTec...\n",
      "21269    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "2335     Clinical Information:\\nFrequent urination, lef...\n",
      "                               ...                        \n",
      "16077    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "8513     Clinical Information:\\nCough.\\nTechnique:\\n1.5...\n",
      "13519    Clinical Information:\\nNot given.\\nTechnique:\\...\n",
      "15969    Clinical Information:\\nOperated breast ca, con...\n",
      "20226    Clinical Information:\\nNodule?\\nTechnique:\\nSe...\n",
      "Name: Correct Items, Length: 250, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22445,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toAnnotate = [\"errorFree\", \"Extraneous Statement\"]\n",
    "# These need to be hand-annotated as they may be harder to computationally add.\n",
    "\n",
    "for error in toAnnotate:\n",
    "    filteredDF = itemsToChange.sample(THRESHOLD, random_state=RANDOM_SEED)\n",
    "    print(f\"Filtered by {error}:\\n\", filteredDF)\n",
    "    filteredDF = filteredDF.to_frame(\"Original\")\n",
    "    # Remove items from itemsToChange\n",
    "    itemsToChange.drop(filteredDF.index, inplace=True)\n",
    "    filteredDF[\"Changed\"] = np.nan\n",
    "    filteredDF[\"ErrorType\"] = np.nan\n",
    "    filteredDF[\"ErrorExplanation\"] = np.nan\n",
    "    filteredDF[\"ErrorPhrases\"] = np.nan\n",
    "    filteredDF.to_csv(f\"datasets/training_{error}.csv\")\n",
    "itemsToChange.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b2d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ii_dataset = pd.read_csv(\"datasets/training_Internal Inconsistency.csv\")\n",
    "\n",
    "# Detokenises the sentence back together\n",
    "twd = nltk.TreebankWordDetokenizer()\n",
    "\n",
    "dataToChange = ii_dataset[\"Original\"]\n",
    "\n",
    "def reportCorrection(report: str)-> tuple[RadiologyError, str]:\n",
    "  \"\"\"Go through each sentence and check if there is an internal inconsistency keyword, by turning it into a set. Use the intersection between the omission + the sentence. Check whether each sentence in the dataset is \"\"\"\n",
    "  tokenised = nltk.sent_tokenize(report)\n",
    "  for index in range(len(tokenised)):\n",
    "      sentence = tokenised[index]\n",
    "      intersect = set(sideConfusionDict.keys()).intersection(set(sentence.split(\" \")))\n",
    "      if len(intersect) > 0:\n",
    "          # Take the first element of the sentence and use the replace function to find the replacement word.\n",
    "          word = random.choice(list(intersect))\n",
    "          replacementList = list(sideConfusionDict[word])\n",
    "          # Omission would have the replace == an empty string.\n",
    "          replace = random.choice(replacementList)\n",
    "          newSentence = sentence.replace(word, replace, 1)\n",
    "          print(f\"Old sentence = {sentence}\\nNew sentence = {newSentence}\")\n",
    "          tokenised[index] = newSentence\n",
    "          break\n",
    "\n",
    "  newError = RadiologyError(\n",
    "      errorType=ErrorType.InternalInconsistency,\n",
    "      errorPhrases=[newSentence],\n",
    "      errorExplanation=[\n",
    "          f\"There is an internal inconsistency, as {replace} should be {word}.\"\n",
    "      ],\n",
    "  )\n",
    "  return newError, twd.detokenize(tokenised)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hons",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
