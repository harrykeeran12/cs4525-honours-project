{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "B2tfGgx1XJ1m"
      },
      "outputs": [],
      "source": [
        "!pip install -q colab-xterm ollama pydantic huggingface_hub datasets\n",
        "%load_ext colabxterm\n",
        "\n",
        "import os\n",
        "import ollama\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from pydantic import BaseModel\n",
        "from typing import List\n",
        "from enum import Enum\n",
        "from tqdm import trange\n",
        "import IPython"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install ollama and set the model download location to Colab's directory.\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "!export OLLAMA_FLASH_ATTENTION=1\n",
        "!export OLLAMA_KV_CACHE_TYPE=\"q8_0\"\n",
        "!export OLLAMA_CONTEXT_LENGTH=\"4096\"\n",
        "!export OLLAMA_MODELS=\"/content\"\n",
        "!export OLLAMA_DEBUG=1"
      ],
      "metadata": {
        "id": "_PyrfMrj4GOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run ollama in the background using ollama serve &\n",
        "!nohup ollama serve &"
      ],
      "metadata": {
        "id": "bLXAKCPx-8HV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ErrorType(Enum):\n",
        "    \"\"\"Strict definition of the multiple errors that can occur.\"\"\"\n",
        "\n",
        "    TranscriptionError = \"Transcription Error\"\n",
        "    InternalInconsistency = \"Internal Inconsistency\"\n",
        "    Omission = \"Omission\"\n",
        "    ExtraneousStatement = \"Extraneous Statement\"\n",
        "\n",
        "\n",
        "class RadiologyError(BaseModel):\n",
        "    \"\"\"This class serves as a schema to act as structured output for the models.\"\"\"\n",
        "\n",
        "    errorType: ErrorType\n",
        "    errorPhrases: list[str]\n",
        "    errorExplanation: list[str]\n",
        "\n",
        "\n",
        "class RadiologyErrors(BaseModel):\n",
        "    \"\"\"Adding multiple errors for structured output.\"\"\"\n",
        "\n",
        "    errorsForWholeText: List[RadiologyError] | None\n",
        "\n"
      ],
      "metadata": {
        "id": "6q1HNvcE3dpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import time\n",
        "import os\n",
        "\n",
        "os.environ['OLLAMA_FLASH_ATTENTION'] = \"1\"\n",
        "os.environ[\"OLLAMA_KV_CACHE_TYPE\"] = \"q8_0\"\n",
        "os.environ[\"OLLAMA_CONTEXT_LENGTH\"] = \"4096\"\n",
        "os.environ[\"OLLAMA_MODELS\"] = \"/content\"\n",
        "\n",
        "time.sleep(10)\n",
        "\n",
        "model_names = [\"mistral:latest\", \"qwen2.5:latest\", \"falcon3:latest\"]\n",
        "# model_names = [\"hf.co/harrykeeran12/radiology_error_mistral_gguf:Q4_K_M\"]\n",
        "\n",
        "dataframe = pd.read_csv(\"testing_data.csv\")\n",
        "\n",
        "removedCorrection = dataframe[\"Removed Correction\"]\n",
        "\n",
        "SYSTEM = \"\"\"You help correct radiology report errors. These include omissions, extraneous statements, transcription errors and internal  inconsistencies. For each mistake, show the incorrect words and explain what the problem is.\"\"\"\n",
        "\n",
        "SYSTEM2 = \"\"\"You help correct radiology report errors in an isolated local system. When provided with a free-text radiology report, analyze it for:\n",
        "- Omissions: Missing critical information that should be present\n",
        "- Extraneous statements: Information that doesn't belong or is redundant including any template errors.\n",
        "- Transcription errors: Spelling, punctuation, or terminology mistakes - Internal inconsistencies: Contradictory statements within the report. For each identified error, return:\n",
        "1. The error type\n",
        "2. The exact text containing the error\n",
        "3. An explanation of why it's an error\n",
        "The arrays must be consistent (each error needs all three elements). Ignore any errors deemed redundant. Output JSON.\"\"\"\n",
        "\n",
        "SYSTEM3 = \"\"\"Your task is to identify errors in unstructured radiology reports including omissions, extraneous statements, transcription errors, and internal inconsistencies. Analyze each report and output errors in JSON format.\n",
        "\n",
        "Example 1:\n",
        "Input: \"Clinical Information:\\nNot given.\\nTechnique:\\nNon-contrast images were taken in the axial plane with a section thickness of 1.5 m.\\nFindings:\\nOther findings are stable.\\nImpressions: \\nNot given.\"\n",
        "\n",
        "Output: {\n",
        "    \"errorsForWholeText\": {\n",
        "        \"errorType\": \"Transcription Error\",\n",
        "        \"errorPhrases\": [\n",
        "            \"Non-contrast images were taken in the axial plane with a section thickness of 1.5 m.\"\n",
        "        ],\n",
        "        \"errorExplanation\": [\n",
        "            \"The section thickness would normally be in millimetres not metres.\"\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "Example 2:\n",
        "Input: \"Clinical Information:\\nPatient with chronic headaches.\\nTechnique:\\nMRI of the brain without contrast.\\nFindings:\\nNo acute intracranial abnormality.\\nNo evidence of mass effect or midline shift.\\nVentricles are normal in size and configuration.\\nImpressions:\\nNormal brain MRI.\"\n",
        "\n",
        "Output: {\n",
        "    \"errorsForWholeText\": \"No errors found\"\n",
        "}\n",
        "\n",
        "Example 3:\n",
        "Input: \"Clinical Information:\\nFall from standing height.\\nTechnique:\\nCT scan of the right wrist.\\nFindings:\\nThere is a comminuted fracture of the distal radius.\\nNo evidence of dislocation.\\nImpressions:\\nThe patient has a sprained wrist.\"\n",
        "\n",
        "Output: {\n",
        "    \"errorsForWholeText\": {\n",
        "        \"errorType\": \"Internal Inconsistency\",\n",
        "        \"errorPhrases\": [\n",
        "            \"There is a comminuted fracture of the distal radius.\",\n",
        "            \"The patient has a sprained wrist.\"\n",
        "        ],\n",
        "        \"errorExplanation\": [\n",
        "            \"The findings section identifies a fracture, but the impressions section only mentions a sprain, which is inconsistent.\"\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "Analyse the report below:\"\"\"\n",
        "\n",
        "for m in model_names:\n",
        "  !ollama pull {m}\n"
      ],
      "metadata": {
        "id": "o3OQZFeo5Rrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(x:str, MODEL_NAME:str, SYSTEM:str):\n",
        "  \"\"\"Performs inferences over a dataset using ollama and the GPU on the cloud system.\"\"\"\n",
        "\n",
        "  return ollama.generate(\n",
        "          model=MODEL_NAME,\n",
        "          system=SYSTEM,\n",
        "          prompt=x,\n",
        "          options={\"temperature\": 0},\n",
        "          format=RadiologyErrors.model_json_schema(),\n",
        "      )[\"response\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "bOCa3EHjk3h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inferences = [\"\" for i in dataframe[\"Removed Correction\"]]"
      ],
      "metadata": {
        "id": "IF4d25Zg7v86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for modelName in model_names:\n",
        "  for index in trange(len(inferences)):\n",
        "    if inferences[index] == \"\":\n",
        "      print(removedCorrection[index])\n",
        "      resp = inference(removedCorrection[index],modelName, SYSTEM3)\n",
        "      print(resp)\n",
        "      inferences[index] = resp\n",
        "    else:\n",
        "      continue\n",
        "  dataframe[modelName] = inferences\n",
        "  dataframe.to_csv(f\"{modelName}_inference_prompt3.csv\")\n"
      ],
      "metadata": {
        "id": "JRr56b595ZmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill ollama"
      ],
      "metadata": {
        "id": "26zkS8tT_qnQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}